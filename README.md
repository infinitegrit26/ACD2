# PDF Chatbot with Google ADK

A professional, production-ready PDF chatbot built with Google Agent Development Kit (ADK), OpenAI models, ChromaDB, and Streamlit. Upload PDFs and interact with them using an intelligent agent that knows when to search documents and when to respond directly.

## ğŸ—ï¸ Architecture Overview

### System Components

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Streamlit Frontend                      â”‚
â”‚  â€¢ File Upload UI    â€¢ Chat Interface    â€¢ Stats Display   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Google ADK Agent                         â”‚
â”‚  â€¢ LiteLlm Connector (OpenAI Bridge)                       â”‚
â”‚  â€¢ Smart Routing Logic                                      â”‚
â”‚  â€¢ Tool Decision Making                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                                â”‚
         â”‚ (General Questions)            â”‚ (Document Questions)
         â”‚                                â”‚
         â–¼                                â–¼
    Direct Response              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    (No Tool Call)               â”‚  Vector DB Tool  â”‚
                                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â”‚
                                          â–¼
                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                            â”‚    ChromaDB (Persistent) â”‚
                            â”‚  â€¢ OpenAI Embeddings     â”‚
                            â”‚  â€¢ Semantic Search       â”‚
                            â”‚  â€¢ Duplicate Detection   â”‚
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow

#### 1. PDF Upload Flow
```
User Upload PDF
    â†“
Validate PDF (pypdf)
    â†“
Extract Text (pypdf)
    â†“
Chunk Text (RecursiveCharacterTextSplitter)
    â”œâ”€â”€ chunk_size: 1000 chars
    â””â”€â”€ overlap: 200 chars
    â†“
Generate Embeddings (OpenAI text-embedding-3-large)
    â†“
Check for Duplicates (SHA-256 hash)
    â†“
Store in ChromaDB (./chroma_data/)
```

#### 2. Chat Query Flow
```
User Input
    â†“
Google ADK Agent Analyzes Query
    â†“
Decision Point:
    â”œâ”€â”€â”€ General Question? â”€â”€â†’ Direct Response (No Tool)
    â”‚    (e.g., "Hello", "What is AI?")
    â”‚
    â””â”€â”€â”€ Document Question? â”€â”€â†’ Use query_vector_db Tool
         (e.g., "What does the doc say about X?")
              â†“
         Generate Query Embedding
              â†“
         Semantic Search in ChromaDB
              â†“
         Retrieve Top-K Chunks
              â†“
         Format Context for Agent
              â†“
         Agent Generates Response
              â†“
         Cites Document Source
```

## ğŸš€ Features

### Smart Agent Routing
The Google ADK agent is configured with intelligent routing logic:
- **Handles internally**: Greetings, general AI questions, casual conversation
- **Invokes tool**: Questions about uploaded document content only
- **Decision transparency**: User sees "Thinking..." spinner during tool decisions

### Robust PDF Processing
- **Text Extraction**: Uses `pypdf` for reliable PDF parsing
- **Smart Chunking**: Recursive character-based splitting with semantic boundaries
- **Overlap Strategy**: 200-character overlap prevents context loss

### Persistent Vector Storage
- **ChromaDB**: Persistent storage in `./chroma_data/`
- **Duplicate Detection**: SHA-256 hashing prevents re-processing
- **OpenAI Embeddings**: High-quality `text-embedding-3-large` model

### Production Standards
- âœ… Type hints throughout
- âœ… Structured logging (no print statements)
- âœ… Pydantic-based configuration
- âœ… Error handling and validation
- âœ… Modular, testable architecture

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ .env                          # Environment variables
â”œâ”€â”€ .gitignore                    # Git ignore patterns
â”œâ”€â”€ pyproject.toml                # UV package configuration
â”œâ”€â”€ README.md                     # This file
â”‚
â””â”€â”€ src/
    â”œâ”€â”€ main.py                   # Streamlit application entry point
    â”œâ”€â”€ config.py                 # Pydantic Settings configuration
    â”‚
    â”œâ”€â”€ agent/
    â”‚   â”œâ”€â”€ core.py              # Google ADK Agent setup with LiteLlm
    â”‚   â””â”€â”€ tools.py             # Vector DB query tool implementation
    â”‚
    â”œâ”€â”€ database/
    â”‚   â””â”€â”€ chroma.py            # ChromaDB client and operations
    â”‚
    â””â”€â”€ utils/
        â””â”€â”€ pdf_helper.py        # PDF processing and text chunking
```

## ğŸ› ï¸ Setup Instructions

### Prerequisites
- Python 3.10+
- [uv](https://github.com/astral-sh/uv) package manager
- OpenAI API key

### Installation

1. **Clone and navigate to the project:**
   ```bash
   cd c:\ACD\ACD2
   ```

2. **Install dependencies with uv:**
   ```bash
   uv pip install -e .
   ```

3. **Configure environment variables:**
   Edit `.env` file with your OpenAI API key:
   ```env
   OPENAI_API_KEY=sk-your-actual-key-here
   LLM_MODEL=gpt-4o-mini
   EMBEDDING_MODEL=text-embedding-3-large
   CHROMA_PERSIST_DIRECTORY=./chroma_data
   LOG_LEVEL=INFO
   ```

4. **Run the application:**
   ```bash
   streamlit run src/main.py
   ```

5. **Access the UI:**
   Open your browser to `http://localhost:8501`

## ğŸ“– Usage Guide

### Uploading PDFs
1. Click **"Browse files"** in the sidebar
2. Select one or more PDF files
3. Wait for processing (you'll see chunk count)
4. Files are automatically deduplicated

### Chatting with Documents
**The agent intelligently routes your questions:**

**General questions (no tool call):**
- "Hello!" â†’ Direct greeting
- "What is machine learning?" â†’ Direct explanation
- "Tell me about yourself" â†’ Direct response

**Document questions (uses query_vector_db tool):**
- "What does this document say about X?"
- "Summarize the uploaded PDF"
- "Find information about Y in the documents"

### Understanding Agent Behavior

#### Smart Routing Configuration
In [src/agent/core.py](src/agent/core.py), the agent is configured with:

```python
system_prompt = """You are a helpful AI assistant with access to uploaded PDF documents.

IMPORTANT ROUTING RULES:
1. For general questions, greetings, or conversations about AI/technology 
   that are NOT about the uploaded documents, respond directly WITHOUT using any tools.
2. ONLY use the query_vector_db tool when the user asks questions specifically 
   about content in the uploaded PDFs.
"""
```

#### LiteLlm Integration
The agent uses **Google ADK with LiteLlm** to bridge OpenAI models:

```python
from google.adk.models import LiteLlm

model = LiteLlm(
    model_name=f"openai/{self.config.llm_model}",
    api_key=self.config.openai_api_key
)

agent = Agent(
    model=model,
    system_instruction=system_prompt,
    tools=[query_vector_db_tool]
)
```

This allows seamless use of OpenAI's `gpt-4o-mini` within the Google ADK framework.

## ğŸ”§ Configuration Options

### config.py Settings
| Parameter | Default | Description |
|-----------|---------|-------------|
| `llm_model` | `gpt-4o-mini` | OpenAI model for agent |
| `embedding_model` | `text-embedding-3-large` | OpenAI embedding model |
| `chunk_size` | `1000` | Characters per chunk |
| `chunk_overlap` | `200` | Overlap between chunks |
| `chroma_persist_directory` | `./chroma_data` | Vector DB storage path |

### Customizing Chunking
Edit in [src/utils/pdf_helper.py](src/utils/pdf_helper.py):
```python
self.text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,      # Adjust for your documents
    chunk_overlap=200,    # Adjust for context preservation
    separators=["\n\n", "\n", ". ", " ", ""]  # Customize split priority
)
```

## ğŸ§ª Testing the System

### Test Smart Routing
1. **General Question**: "Hello, how are you?"
   - Expected: Direct response, no tool call
   
2. **Document Question**: "What is the main topic of the document?"
   - Expected: "Thinking..." spinner, uses `query_vector_db`, cites source

### Test Duplicate Detection
1. Upload a PDF file
2. Upload the same file again
3. Expected: "Already processed" message

### Test Edge Cases
- Upload an empty PDF
- Ask questions before uploading any documents
- Upload corrupted files

## ğŸ” Logging and Debugging

### View Logs
Logs are output to console with timestamps:
```
2026-02-04 10:30:15 - database.chroma - INFO - ChromaDB initialized with 0 documents
2026-02-04 10:30:20 - agent.core - INFO - PDF Chat Agent initialized successfully
```

### Adjust Log Level
In `.env`:
```env
LOG_LEVEL=DEBUG  # For detailed debugging
LOG_LEVEL=INFO   # For production
```

## ğŸ” Security Considerations

- **API Keys**: Never commit `.env` to version control
- **File Validation**: All PDFs are validated before processing
- **Error Handling**: Graceful fallbacks for all operations
- **Input Sanitization**: User inputs are safely handled

## ğŸš§ Troubleshooting

### Common Issues

**"No module named 'google.adk'"**
```bash
uv pip install google-adk
```

**"OpenAI API key not found"**
- Check `.env` file exists and contains `OPENAI_API_KEY`
- Ensure no spaces around the `=` in `.env`

**"ChromaDB permission error"**
- Ensure `./chroma_data` directory is writable
- Check disk space availability

**"PDF extraction failed"**
- Verify PDF is not password-protected
- Some scanned PDFs may have no extractable text

## ğŸ“Š Performance Considerations

### Scaling Recommendations
- **Large PDFs**: Consider increasing `chunk_size` to reduce chunk count
- **Many Files**: ChromaDB scales to millions of vectors
- **Query Speed**: Adjust `n_results` parameter (default: 5)

### Resource Usage
- **Memory**: ~100-500MB depending on loaded documents
- **Disk**: Varies with document count (embeddings stored on disk)
- **API Costs**: 
  - Embeddings: ~$0.13 per 1M tokens
  - LLM queries: ~$0.15-0.60 per 1M tokens (GPT-4o-mini)

## ğŸ¤ Contributing

### Code Standards
- Follow PEP 8 style guidelines
- Add type hints to all functions
- Use structured logging (not print)
- Write docstrings for public APIs

### Testing
```bash
# Run with pytest (once tests are added)
pytest tests/
```

## ğŸ“ License

This project is provided as-is for educational and commercial use.

## ğŸ™ Acknowledgments

- **Google ADK**: Agent development framework
- **OpenAI**: LLM and embedding models
- **ChromaDB**: Vector database
- **Streamlit**: UI framework
- **pypdf**: PDF processing library

## ğŸ“ Support

For issues or questions:
1. Check the troubleshooting section above
2. Review logs in the console
3. Verify `.env` configuration
4. Ensure all dependencies are installed

---

**Built with â¤ï¸ using Google ADK, OpenAI, and ChromaDB**
